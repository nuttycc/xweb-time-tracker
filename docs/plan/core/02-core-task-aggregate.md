# Core Logic task plan: Data Aggregation - v1.5

Status：🔄 In Progress

## Scope

**ONLY INCLUDE**:

数据聚合模块

- 数据聚合
- 可配置的 event logs 清理器
- 聚合和清理的任务调度

**Explicitly EXCLUDE**:

- 数据库基础设施（已在 `01-core-task-db.md` 中完成）。
- 时间追踪（`Time Tracking`）的事件生成逻辑。
- 用户配置（`User Configuration`）的读取与管理逻辑。
- 任何 UI/UX 相关的功能。

## Reference

### docs

- docs\plan\core\01-core-task-db.md
- docs\specs\base\5-CSPEC.md

### mermaid

- docs\specs\mermaid\01\timeflow-arch.mmd
- docs\specs\mermaid\02\ASA.mmd
- docs\specs\mermaid\02\PDP.mmd
- docs\specs\mermaid\02\TTC.mmd

## Task Overview

数据聚合模块是连接时间追踪和数据查询的核心桥梁，负责将原始事件日志转换为可查询的统计数据。此计划将专注于以下四个核心领域：

### 数据流架构

```
时间追踪模块 -> eventslog表 -> event聚合引擎 -> aggregatedstats表 -> 数据查询模块
     ↓              ↓             ↓               ↓                   ↓
  事件生成     DB-原始事件存储   聚合处理      DB-统计数据存储           UI
```

## Tasks

### 阶段1：聚合引擎基础架构

此阶段的目标是建立数据聚合引擎的核心架构，实现从原始事件到统计数据的完整转换流程。

- [ ] **1. 聚合引擎基础架构** → 构建数据聚合的核心逻辑基础，包含类结构定义、核心算法实现和错误处理能力。

  - [ ] **1.1 创建聚合引擎类结构与接口定义**
        → 设计并实现 `AggregationEngine` 类的基础结构，定义所有核心方法的接口签名和类型定义。
        → 建立聚合模块的核心架构，为后续具体实现提供清晰的接口规范。
        → 验收标准：完整的TypeScript类文件，包含所有方法签名、参数类型、返回类型定义。

  - [ ] **1.2 实现增量聚合与时间累积计算核心算法**
        → 实现基于isProcessed字段的增量聚合机制（获取未处理事件→处理→标记已处理）。
        → 实现完整的时间累积计算逻辑：按visitId分组计算Open Time、按activityId分组计算Active Time，处理start/checkpoint/end事件序列的时间片段累加，支持Checkpoint增量计算和孤儿会话处理。
        → 验收标准：算法能正确处理事件序列的时间累积计算，支持checkpoint增量和异常情况处理。

  - [ ] **1.3 实现域名解析与错误处理机制**
        → 开发URL域名解析功能，使用PSL（Public Suffix List）提取hostname和parentDomain。
        → 添加完整的错误处理机制，包含错误捕获、日志记录和异常恢复。
        → 确保聚合过程稳定性，符合文档"错误恢复(基本)"要求。
        → 验收标准：域名解析功能完整，错误处理机制健全，通过测试验证。

### 阶段2：聚合调度器与任务管理

此阶段的目标是建立自动化的聚合调度系统，确保数据聚合的定期执行和可靠性。

- [ ] **2. 聚合调度器与任务管理** → 实现基于Chrome扩展的聚合调度器，管理定时聚合任务的执行、监控和配置，确保数据聚合的自动化和可靠性。

  - [ ] **2.1 实现Chrome.alarms调度系统**
        → 基于chrome.alarms API构建后台任务调度机制，支持可配置的聚合间隔（默认60分钟）。
        → 实现调度器的启动、停止、重置功能，确保扩展生命周期管理的正确性。
        → 验收标准：调度系统能正确创建和管理chrome.alarms，支持配置参数动态调整。

  - [ ] **2.2 建立任务队列与并发控制机制**
        → 实现任务状态管理，防止聚合任务的重复执行和并发冲突。
        → 建立任务队列系统，支持任务排队和优先级管理。
        → 添加任务执行锁机制，确保同一时间只有一个聚合任务在运行。
        → 验收标准：并发控制机制有效，任务不会重复执行，队列管理正常工作。

  - [ ] **2.3 实现任务监控与重试机制**
        → 建立任务执行状态监控，记录执行日志和性能指标。
        → 实现智能重试机制，处理聚合失败的情况。
        → 添加任务超时检测和异常恢复功能。
        → 验收标准：监控系统完整，重试机制可靠，异常情况能正确处理和恢复。

### 阶段3：数据清理器与保留策略

此阶段的目标是建立数据生命周期管理系统，优化存储空间和查询性能。

- [ ] **3. 数据清理器与保留策略** → 实现数据清理器组件，根据用户配置和系统策略自动清理过期的原始事件数据，优化存储空间和查询性能。

  - [ ] **3.1 实现可配置的数据保留策略**
        → 设计和实现数据保留策略配置系统，支持按时间、按数量等维度的清理规则。
        → 建立策略验证机制，确保配置的合理性和安全性。
        → 集成到现有配置系统，提供用户友好的配置界面。
        → 验收标准：保留策略配置完整，支持多种清理维度，配置验证机制有效。

  - [ ] **3.2 建立安全的数据清理机制**
        → 实现数据清理的核心逻辑，确保只清理已聚合且超过保留期的原始事件数据。
        → 建立数据清理前的安全检查，防止误删未聚合的重要数据。
        → 实现批量清理和事务性删除，确保数据一致性。
        → 验收标准：清理机制安全可靠，不会误删数据，支持批量处理。

  - [ ] **3.3 实现清理任务调度与性能优化**
        → 集成清理任务到聚合调度器，实现定期自动清理。
        → 实现清理任务的性能优化，包括分批处理和进度监控。
        → 建立清理操作的日志记录和统计报告。
        → 验收标准：清理任务调度正常，性能优化有效，日志记录完整。

### 阶段4：系统集成与性能优化

此阶段的目标是完成整个数据聚合模块的集成，建立错误恢复和性能优化机制。

- [ ] **4. 系统集成与性能优化** → 完成数据聚合模块的系统集成，实现性能优化和错误恢复机制，确保整个聚合系统的稳定性和高效性。

  - [ ] **4.1 完成系统组件集成与协调机制**
        → 集成聚合引擎、调度器、数据清理器为统一的聚合系统。
        → 建立组件间的通信和协调机制，确保各组件协同工作。
        → 实现系统启动、停止、重启的完整生命周期管理。
        → 验收标准：系统集成完整，组件协调正常，生命周期管理有效。

  - [ ] **4.2 实现全局错误恢复与重试机制**
        → 建立全局错误处理框架，统一处理各组件的异常情况。
        → 实现智能重试策略，包括指数退避和最大重试次数限制。
        → 建立错误恢复机制，确保系统能从各种故障中自动恢复。
        → 验收标准：错误处理机制完善，重试策略有效，系统恢复能力强。

  - [ ] **4.3 建立性能监控与优化机制**
        → 实现系统性能监控，包括聚合速度、内存使用、数据库性能等指标。
        → 建立性能优化机制，包括批量处理优化、事务管理优化、内存使用优化。
        → 实现性能报告和预警系统，及时发现和处理性能问题。
        → 验收标准：性能监控完整，优化机制有效，系统运行高效稳定。

## Major Changes
